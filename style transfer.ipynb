{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59c5f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65c6e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_image(path, img_transforms, size = (300,300)):\n",
    "    image = Image.open(path)\n",
    "    image = image.resize(size, Image.Resampling.LANCZOS)\n",
    "    image = img_transforms(image).unsqueeze(0)\n",
    "    return image.to(device)\n",
    "def get_gram(m):\n",
    "    # m is shape (1,C,H,W)\n",
    "    _, c, h, w = m.size()\n",
    "    m = m.view(c, h*w)\n",
    "    m = torch.mm(m, m.t())\n",
    "    return m\n",
    "def denormalize_img(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0)) #C,H,W -> H,W,C\n",
    "    mean = np.array([0.485, 0.456, 0.406]) \n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std*inp + mean\n",
    "    inp = np.clip(inp,0,1)\n",
    "    return inp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "211975ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeaturesExtractor, self).__init__()\n",
    "        self.selected_layers = [3,8,15,22]\n",
    "        self.vgg = models.vgg16(pretrained = True).features\n",
    "    def forward(self,x):\n",
    "        layer_feats = []\n",
    "        for num, layer in self.vgg._modules.items():\n",
    "            x = layer(x)\n",
    "            if int(num) in self.selected_layers:\n",
    "                layer_feats.append(x)\n",
    "        return layer_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f73cc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "282c872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = get_image('style.jpg', img_transforms)\n",
    "content_image = get_image('content.jpg', img_transforms)\n",
    "generate_image = content_image.clone()\n",
    "\n",
    "generate_image.requires_grad = True\n",
    "optimizer = torch.optim.Adam([generate_image], lr=3e-3,betas = [0.5,0.999])\n",
    "encoder = FeaturesExtractor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc1d02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in encoder.parameters():\n",
    "    p.requires_grad = False #freezingthe layers. encoder.eval() also works\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a156493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\tContent Loss: 2.8667\tStyle Loss: 306.9382\n",
      "Epoch [10]\tContent Loss: 2.8731\tStyle Loss: 296.0386\n",
      "Epoch [20]\tContent Loss: 2.8790\tStyle Loss: 285.5115\n",
      "Epoch [30]\tContent Loss: 2.8844\tStyle Loss: 275.3465\n",
      "Epoch [40]\tContent Loss: 2.8894\tStyle Loss: 265.5317\n",
      "Epoch [50]\tContent Loss: 2.8945\tStyle Loss: 256.0580\n",
      "Epoch [60]\tContent Loss: 2.8986\tStyle Loss: 246.9178\n",
      "Epoch [70]\tContent Loss: 2.9029\tStyle Loss: 238.1077\n",
      "Epoch [80]\tContent Loss: 2.9075\tStyle Loss: 229.6163\n",
      "Epoch [90]\tContent Loss: 2.9121\tStyle Loss: 221.4362\n",
      "Epoch [100]\tContent Loss: 2.9163\tStyle Loss: 213.5622\n",
      "Epoch [110]\tContent Loss: 2.9202\tStyle Loss: 205.9820\n",
      "Epoch [120]\tContent Loss: 2.9240\tStyle Loss: 198.6911\n",
      "Epoch [130]\tContent Loss: 2.9274\tStyle Loss: 191.6786\n",
      "Epoch [140]\tContent Loss: 2.9303\tStyle Loss: 184.9445\n",
      "Epoch [150]\tContent Loss: 2.9328\tStyle Loss: 178.4767\n",
      "Epoch [160]\tContent Loss: 2.9355\tStyle Loss: 172.2651\n",
      "Epoch [170]\tContent Loss: 2.9377\tStyle Loss: 166.3086\n",
      "Epoch [180]\tContent Loss: 2.9394\tStyle Loss: 160.5986\n",
      "Epoch [190]\tContent Loss: 2.9411\tStyle Loss: 155.1279\n",
      "Epoch [200]\tContent Loss: 2.9431\tStyle Loss: 149.8906\n",
      "Epoch [210]\tContent Loss: 2.9449\tStyle Loss: 144.8808\n",
      "Epoch [220]\tContent Loss: 2.9470\tStyle Loss: 140.0863\n",
      "Epoch [230]\tContent Loss: 2.9496\tStyle Loss: 135.4989\n",
      "Epoch [240]\tContent Loss: 2.9524\tStyle Loss: 131.1127\n",
      "Epoch [250]\tContent Loss: 2.9551\tStyle Loss: 126.9219\n",
      "Epoch [260]\tContent Loss: 2.9576\tStyle Loss: 122.9189\n",
      "Epoch [270]\tContent Loss: 2.9599\tStyle Loss: 119.0928\n",
      "Epoch [280]\tContent Loss: 2.9626\tStyle Loss: 115.4383\n",
      "Epoch [290]\tContent Loss: 2.9655\tStyle Loss: 111.9501\n",
      "Epoch [300]\tContent Loss: 2.9680\tStyle Loss: 108.6201\n",
      "Epoch [310]\tContent Loss: 2.9704\tStyle Loss: 105.4393\n",
      "Epoch [320]\tContent Loss: 2.9729\tStyle Loss: 102.4019\n",
      "Epoch [330]\tContent Loss: 2.9751\tStyle Loss: 99.5023\n",
      "Epoch [340]\tContent Loss: 2.9772\tStyle Loss: 96.7349\n",
      "Epoch [350]\tContent Loss: 2.9792\tStyle Loss: 94.0935\n",
      "Epoch [360]\tContent Loss: 2.9811\tStyle Loss: 91.5731\n",
      "Epoch [370]\tContent Loss: 2.9829\tStyle Loss: 89.1669\n",
      "Epoch [380]\tContent Loss: 2.9844\tStyle Loss: 86.8691\n",
      "Epoch [390]\tContent Loss: 2.9857\tStyle Loss: 84.6729\n",
      "Epoch [400]\tContent Loss: 2.9873\tStyle Loss: 82.5731\n",
      "Epoch [410]\tContent Loss: 2.9888\tStyle Loss: 80.5658\n",
      "Epoch [420]\tContent Loss: 2.9905\tStyle Loss: 78.6460\n",
      "Epoch [430]\tContent Loss: 2.9923\tStyle Loss: 76.8107\n",
      "Epoch [440]\tContent Loss: 2.9944\tStyle Loss: 75.0546\n",
      "Epoch [450]\tContent Loss: 2.9964\tStyle Loss: 73.3739\n",
      "Epoch [460]\tContent Loss: 2.9985\tStyle Loss: 71.7639\n",
      "Epoch [470]\tContent Loss: 3.0004\tStyle Loss: 70.2210\n",
      "Epoch [480]\tContent Loss: 3.0021\tStyle Loss: 68.7416\n",
      "Epoch [490]\tContent Loss: 3.0035\tStyle Loss: 67.3227\n",
      "Epoch [500]\tContent Loss: 3.0051\tStyle Loss: 65.9610\n",
      "Epoch [510]\tContent Loss: 3.0067\tStyle Loss: 64.6538\n",
      "Epoch [520]\tContent Loss: 3.0084\tStyle Loss: 63.3968\n",
      "Epoch [530]\tContent Loss: 3.0101\tStyle Loss: 62.1884\n",
      "Epoch [540]\tContent Loss: 3.0116\tStyle Loss: 61.0259\n",
      "Epoch [550]\tContent Loss: 3.0132\tStyle Loss: 59.9061\n",
      "Epoch [560]\tContent Loss: 3.0147\tStyle Loss: 58.8277\n",
      "Epoch [570]\tContent Loss: 3.0164\tStyle Loss: 57.7878\n",
      "Epoch [580]\tContent Loss: 3.0181\tStyle Loss: 56.7845\n",
      "Epoch [590]\tContent Loss: 3.0202\tStyle Loss: 55.8160\n",
      "Epoch [600]\tContent Loss: 3.0222\tStyle Loss: 54.8800\n",
      "Epoch [610]\tContent Loss: 3.0243\tStyle Loss: 53.9746\n",
      "Epoch [620]\tContent Loss: 3.0261\tStyle Loss: 53.0993\n",
      "Epoch [630]\tContent Loss: 3.0280\tStyle Loss: 52.2525\n",
      "Epoch [640]\tContent Loss: 3.0298\tStyle Loss: 51.4334\n",
      "Epoch [650]\tContent Loss: 3.0314\tStyle Loss: 50.6393\n",
      "Epoch [660]\tContent Loss: 3.0330\tStyle Loss: 49.8690\n",
      "Epoch [670]\tContent Loss: 3.0345\tStyle Loss: 49.1211\n",
      "Epoch [680]\tContent Loss: 3.0361\tStyle Loss: 48.3947\n",
      "Epoch [690]\tContent Loss: 3.0377\tStyle Loss: 47.6890\n",
      "Epoch [700]\tContent Loss: 3.0395\tStyle Loss: 47.0030\n",
      "Epoch [710]\tContent Loss: 3.0415\tStyle Loss: 46.3358\n",
      "Epoch [720]\tContent Loss: 3.0436\tStyle Loss: 45.6868\n",
      "Epoch [730]\tContent Loss: 3.0456\tStyle Loss: 45.0552\n",
      "Epoch [740]\tContent Loss: 3.0477\tStyle Loss: 44.4394\n",
      "Epoch [750]\tContent Loss: 3.0499\tStyle Loss: 43.8396\n",
      "Epoch [760]\tContent Loss: 3.0522\tStyle Loss: 43.2547\n",
      "Epoch [770]\tContent Loss: 3.0546\tStyle Loss: 42.6842\n",
      "Epoch [780]\tContent Loss: 3.0572\tStyle Loss: 42.1275\n",
      "Epoch [790]\tContent Loss: 3.0596\tStyle Loss: 41.5839\n",
      "Epoch [800]\tContent Loss: 3.0621\tStyle Loss: 41.0529\n",
      "Epoch [810]\tContent Loss: 3.0645\tStyle Loss: 40.5336\n",
      "Epoch [820]\tContent Loss: 3.0669\tStyle Loss: 40.0259\n",
      "Epoch [830]\tContent Loss: 3.0692\tStyle Loss: 39.5297\n",
      "Epoch [840]\tContent Loss: 3.0713\tStyle Loss: 39.0445\n",
      "Epoch [850]\tContent Loss: 3.0733\tStyle Loss: 38.5695\n",
      "Epoch [860]\tContent Loss: 3.0754\tStyle Loss: 38.1041\n",
      "Epoch [870]\tContent Loss: 3.0778\tStyle Loss: 37.6490\n",
      "Epoch [880]\tContent Loss: 3.0801\tStyle Loss: 37.2029\n",
      "Epoch [890]\tContent Loss: 3.0824\tStyle Loss: 36.7656\n",
      "Epoch [900]\tContent Loss: 3.0846\tStyle Loss: 36.3371\n",
      "Epoch [910]\tContent Loss: 3.0868\tStyle Loss: 35.9173\n",
      "Epoch [920]\tContent Loss: 3.0891\tStyle Loss: 35.5052\n",
      "Epoch [930]\tContent Loss: 3.0915\tStyle Loss: 35.1010\n",
      "Epoch [940]\tContent Loss: 3.0939\tStyle Loss: 34.7048\n",
      "Epoch [950]\tContent Loss: 3.0963\tStyle Loss: 34.3158\n",
      "Epoch [960]\tContent Loss: 3.0989\tStyle Loss: 33.9338\n",
      "Epoch [970]\tContent Loss: 3.1014\tStyle Loss: 33.5588\n",
      "Epoch [980]\tContent Loss: 3.1040\tStyle Loss: 33.1906\n",
      "Epoch [990]\tContent Loss: 3.1064\tStyle Loss: 32.8290\n",
      "Epoch [1000]\tContent Loss: 3.1087\tStyle Loss: 32.4741\n",
      "Epoch [1010]\tContent Loss: 3.1110\tStyle Loss: 32.1251\n",
      "Epoch [1020]\tContent Loss: 3.1130\tStyle Loss: 31.7819\n",
      "Epoch [1030]\tContent Loss: 3.1151\tStyle Loss: 31.4444\n",
      "Epoch [1040]\tContent Loss: 3.1172\tStyle Loss: 31.1125\n",
      "Epoch [1050]\tContent Loss: 3.1193\tStyle Loss: 30.7858\n",
      "Epoch [1060]\tContent Loss: 3.1215\tStyle Loss: 30.4640\n",
      "Epoch [1070]\tContent Loss: 3.1235\tStyle Loss: 30.1474\n",
      "Epoch [1080]\tContent Loss: 3.1255\tStyle Loss: 29.8360\n",
      "Epoch [1090]\tContent Loss: 3.1276\tStyle Loss: 29.5294\n",
      "Epoch [1100]\tContent Loss: 3.1298\tStyle Loss: 29.2272\n",
      "Epoch [1110]\tContent Loss: 3.1319\tStyle Loss: 28.9294\n",
      "Epoch [1120]\tContent Loss: 3.1339\tStyle Loss: 28.6357\n",
      "Epoch [1130]\tContent Loss: 3.1358\tStyle Loss: 28.3463\n",
      "Epoch [1140]\tContent Loss: 3.1378\tStyle Loss: 28.0613\n",
      "Epoch [1150]\tContent Loss: 3.1398\tStyle Loss: 27.7806\n",
      "Epoch [1160]\tContent Loss: 3.1418\tStyle Loss: 27.5042\n",
      "Epoch [1170]\tContent Loss: 3.1439\tStyle Loss: 27.2316\n",
      "Epoch [1180]\tContent Loss: 3.1460\tStyle Loss: 26.9625\n",
      "Epoch [1190]\tContent Loss: 3.1477\tStyle Loss: 26.6969\n"
     ]
    }
   ],
   "source": [
    "content_weight = 1\n",
    "style_weight = 100\n",
    "\n",
    "for epoch in range(1200):\n",
    "    \n",
    "    content_features = encoder(content_image)\n",
    "    style_features = encoder(style_image)\n",
    "    generate_features = encoder(generate_image)\n",
    "    \n",
    "    content_loss = torch.mean((content_features[-1] - generate_features[-1])**2)#content loss uses only the last layer  \n",
    "\n",
    "    style_loss = 0\n",
    "    for gf, sf in zip(generate_features, style_features):\n",
    "        _, c, h, w = gf.size()\n",
    "        gram_gf = get_gram(gf)\n",
    "        gram_sf = get_gram(sf)\n",
    "        style_loss += torch.mean((gram_gf - gram_sf)**2)  / (c * h * w) \n",
    "\n",
    "    loss = content_weight * content_loss + style_weight * style_loss \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print ('Epoch [{}]\\tContent Loss: {:.4f}\\tStyle Loss: {:.4f}'.format(epoch, content_loss.item(), style_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27db0af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "inputs = generate_image.detach().cpu().squeeze()\n",
    "print(inputs.shape)\n",
    "inputs = denormalize_img(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b603cb55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18900\\2066189912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RGB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"your_file.jpeg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "im = Image.fromarray(inputs,\"RGB\")\n",
    "im.save(\"your_file.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4911fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
