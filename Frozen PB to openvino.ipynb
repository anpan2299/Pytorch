{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deaa44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import Markdown\n",
    "import numpy as np\n",
    "\n",
    "model_path = Path(\"./fp32_frezon.pb\")\n",
    "ir_path = Path(model_path).with_suffix(\".xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad15cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer command to convert TensorFlow to OpenVINO:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "`mo --input_model \"fp32_frezon.pb\" --input_shape \"[1,224,224,3]\" --mean_values=\"[127.5,127.5,127.5]\" --scale_values=\"[127.5]\" --data_type FP16 --output_dir \".\"`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting TensorFlow model to IR... This may take a few minutes.\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: C:\\Users\\fp32_frezon.xml\n",
      "[ SUCCESS ] BIN file: C:\\Users\\fp32_frezon.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  Use of deprecated cli option --data_type detected. Option use in the following releases will be fatal. \n",
      "C:\\Users\\realmeid\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\lib\\function_base.py:804: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, order=order, subok=subok, copy=True)\n"
     ]
    }
   ],
   "source": [
    "#1 image of 224x224 RGB\n",
    "mo_command = f\"\"\"mo\n",
    "                 --input_model \"{model_path}\"\n",
    "                 --input_shape \"[1,224,224,3]\" \n",
    "                 --mean_values=\"[127.5,127.5,127.5]\"\n",
    "                 --scale_values=\"[127.5]\"\n",
    "                 --data_type FP16\n",
    "                 --output_dir \"{model_path.parent}\"\n",
    "                 \"\"\"\n",
    "mo_command = \" \".join(mo_command.split())\n",
    "print(\"Model Optimizer command to convert TensorFlow to OpenVINO:\")\n",
    "display(Markdown(f\"`{mo_command}`\"))\n",
    "if not ir_path.exists():\n",
    "    print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
    "    ! $mo_command\n",
    "else:\n",
    "    print(f\"IR model {ir_path} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac2a4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core, Dimension\n",
    "\n",
    "ie = Core()\n",
    "model = ie.read_model(model=ir_path, weights=ir_path.with_suffix(\".bin\"))\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"MULTI:CPU,GPU\") #Full load balance between devices. HETERO:CPU,GPU different hardware units\n",
    "\n",
    "input_key = compiled_model.input(0)\n",
    "\n",
    "#input_key =model.input(0)\n",
    "#shape = input_key.partial_shape\n",
    "#shape[2] = -1 #unbounded dynamic shape\n",
    "#model.reshape({input_key: shape})\n",
    "#compiled_model = ie.compile_model(model=model, device_name=\"MULTI:CPU,GPU\") #Full load balance between devices. HETERO:CPU,GPU different hardware units\n",
    "output_key = compiled_model.output(0)\n",
    "network_input_shape = input_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad81962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Shape: [1,224,224,3]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f582c2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IEPlugin' from 'openvino.inference_engine' (C:\\Users\\realmeid\\Anaconda3\\envs\\py37\\lib\\site-packages\\openvino\\inference_engine\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9960\\4144718584.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mopenvino\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_engine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIENetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIEPlugin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'IEPlugin' from 'openvino.inference_engine' (C:\\Users\\realmeid\\Anaconda3\\envs\\py37\\lib\\site-packages\\openvino\\inference_engine\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image_filename = #\"data/coco_hollywood.jpg\"\n",
    "image = cv2.imread(image_filename)\n",
    "image.shape\n",
    "\n",
    "N, C, H, W = input_key.shape\n",
    "# OpenCV resize expects the destination size as (width, height).\n",
    "resized_image = cv2.resize(src=image, dsize=(W, H))\n",
    "resized_image.shape\n",
    "\n",
    "input_data = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0).astype(np.float32)\n",
    "input_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = compiled_model([input_data])[output_key]\n",
    "\n",
    "request = compiled_model.create_infer_request()\n",
    "request.infer(inputs={input_key.any_name: input_data})\n",
    "result = request.get_output_tensor(output_key.index).data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
